---
layout: post
title: Why I'm Interested in MLOps (Part 1)
date: 2022-02-01 15:40:16
description: 
tags: AI MLOps ENG
categories: MLOps
---

Why I'm Interested in MLOps (Part 1)

Since last year, I've become increasingly fascinated by MLOps. The backstory behind this is quite intriguing... It all goes back to my time working as a Data Scientist (DS) at a previous company, where I primarily focused on building ML models for several years.

Back then, the term "MLOps" didn't exist at all, and individuals with titles like Data Engineers (DE) were mainly responsible for what is now considered MLOps tasks (building data pipelines + deployment). The original responsibilities of DEs primarily revolved around building overall data pipelines, such as ETL and data mart construction, using a skill set primarily based on PL/SQL. Meanwhile, the tasks of DSs mainly involved extracting data and creating statistics or ML models based on business logic (it's worth noting that during that time, DSs were often praised for merely creating models, ultimately leading many down the path of misplaced confidence during the flashy era of instant recognition).

However, a question arises here... Who deployed the models we created? At that time, deployment wasn't given much significance, so tasks were often divided somewhat arbitrarily. For instance, DEs would write deployment-related scripts, while DSs would determine deployment cycles and strategies, implicitly delineating each other's areas of responsibility (eventually blurring the lines between DEs and DSs). During a project at a telecommunications company, for example, we built a massive Hadoop cluster and provided in-house deployment infrastructure, allowing us to deploy models directly on top of it. Companies with resources would develop (fragmented) in-house deployment systems based on open-source tools, while others would utilize external batch tools. Back then, the focus was more on the "performance" of models rather than deployment. Thus, this arrangement was possible. In other words, the emphasis was more on the accuracy of the models, which was the central focus of C-level reports and a key determinant of project success. For instance, if a DS created a model with high accuracy based on certain insights, everyone would be pleased, and deployment would be seen as something that naturally followed.

However, this era where deployment was considered "natural" began to change... Particularly over the past 2-3 years, I've observed an interesting trend where individuals, even those without a graduate degree in ML/DL, often produce excellent models, showcasing their quick wit and prowess. This indicates that the methods for solving real-world problems using ML/DL models have already been largely standardized, and it has become increasingly apparent that applying top-tier research papers from academic conferences to real-world scenarios is challenging. Therefore, the ability to adapt existing models to practical applications has become a more pressing concern, even surpassing concerns about accuracy. As a result, ML/DL is no longer a field that primarily demands research degrees and experience; it has become a field that individuals with excellent analytical skills can also excel in (especially evident in the backgrounds of Kaggle grandmasters, many of whom are practitioners with diverse data experiences but without research degrees).

In this regard, as the barrier to model creation decreases and the focus shifts towards utilizing various standardized libraries and techniques to solve more business problems for more customers more efficiently, I believe we have entered a phase where we need to consider how to realize this in practice. This, I believe, is why MLOps is gaining prominence nowadays. The demand for frameworks that facilitate this realization can be seen in the proliferation of MLOps startups/frameworks, as well as in the annual influx of new services from cloud providers like AWS and the expansion of production capabilities in platforms like PyTorch's high-level APIs and Huggingface's introduction of spaces and acquisition of Gradio.

This trend also leads to a "polarization" in terms of building ML/DL models, where (1) the emphasis is on MLOps + model libraries + domain knowledge, mainly dominated by large enterprise DS/ML teams focusing on efficiency, and (2) the emphasis is on building up research expertise, mainly seen in specialized research organizations or many startups striving to raise the entry barrier. Personally, I believe that amidst this trend, "ambiguous ML/DL modelers" will inevitably fade away... (a somewhat pessimistic view perhaps); thus, I am actively studying to keep up with the latest MLOps techniques, keeping this in mind.

In fact, what's a bit regrettable for me is that, as I've currently shifted away from DS to research and development in Computer Vision, it's challenging for me to experience the exciting MLOps technologies pouring in recently in a practical setting. To overcome this, I'm working on toy projects using frameworks like Metaflow and actively following trends through various blogs and YouTube channels like Chip yuen's. I'm aware that such practical opportunities will surely come back in my career, so I'm preparing myself by understanding the overall trends mentioned above and efficiently studying the latest MLOps techniques for that time.

(Sorce: [Linkedin post](https://www.linkedin.com/in/mark-kim-18431346/recent-activity/all/))