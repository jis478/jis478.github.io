---
layout: post
title: Reflections on the Role of an AI Research Engineer (Part 1)
date: 2023-11-17 12:23:41
description: 
tags: AI StableDiffusion ENG Reflections
categories: AI
---

Reflections on the Role of an AI Research Engineer (Part 1)

At least until early 2022, that's how it was. Especially considering the periods excluding those when I worked closely with the industry during my career.

Let's admit it... Despite working hard, there was undoubtedly an aspect where many AI practitioners, including myself, failed to bridge the gap between academia and industry.

A significant portion of my weekly reports were mainly filled with discussions of experiments and analyses of papers to see if there was a "% performance improvement." Although I brought in the latest SOTA paper models, it was common to face dissatisfaction within my industry or domain, leading me to spend considerable time analyzing the reasons behind it. Occasionally, I found myself justifying this discrepancy with thoughts like "Maybe it's not just about using AI, but also about domain-specific knowledge" and "Perhaps this domain is too easy," amidst sporadic news of AI commercialization.

Even when I worked diligently, if the results were lacking, I often found myself casually dismissing the stress with phrases like "It's a pity, but it can't be helped. It seems this is the current state of the art. Maybe with a little more time..." This led to many projects ending without much pressure on my performance or reputation, focusing instead on the challenge, with some even resulting in applause from colleagues or superiors. Occasionally, I deluded myself into thinking I had achieved something significant, focusing on marginal improvements. (I couldn't help but wonder how challenging it must have been for engineers in AI startups who hadn't experienced this gap...)

In reality, there were instances where I presented a single fine-tuning as a significant achievement to my superiors or within the industry, and of course, in such situations, it was difficult to systematically evaluate AI tasks. Therefore, leveraging this characteristic, I often found myself adjusting the pace of work according to my whims, especially when it came to submitting papers for academic conferences, a luxury unthinkable in other industries. Sometimes, during meet-ups with peers from similar fields, conversations were dominated by a mix of pride and anxiety. Ironically, despite having similar thought patterns myself, I found it challenging to collaborate with colleagues whose tendencies were even more pronounced, constantly striving to find the optimal balance within this environment, aligning with my practical focus on tangible outcomes.

Despite numerous instances where research outcomes from academia failed to meet the demands of industry (be it from operations or customers), many AI tasks were still dependent on academic standards, trapped in a dilemma where there seemed to be no alternative. I believed that this dilemma was well exemplified in joint industry-academia projects. Although we brought industry problems to the table, trying to solve them based on academic standards often resulted in leaving the issues unresolved, merely leaving behind good references, and applauding ourselves, which was a common occurrence. Of course, there might have been other positive effects (such as strategic relationship building), but...

However, with the emergence of Stable-diffusion (or LLM), the situation changed dramatically. It was a watershed moment when AI began to seamlessly integrate into business operations. Apart from applications in different domains, the sheer volume of SD-related attempts pouring in, especially compared to the difficulty of reproducing performances from academic papers, was staggering. Essentially, SD shattered the cartel-like dominance of AI experimentation, which was previously exclusive to researchers, making high-quality image generation and editing accessible to everyone. The reverence once blindly directed towards YouTube channels like Two Minutes Paper or AK tweets discussing papers significantly decreased. Instead, examples receiving numerous upvotes on Reddit garnered attention, and during the era of GANs, even non-specialists actively contributed to both domestic and international communities, resulting in a multitude of outcomes. Consequently, newcomers to the field often turned to Reddit and social media before consulting survey papers.

As the community witnessed an influx of reproducible attempts through collective intelligence, bridging the gap between academia and industry, many organizations began minimizing their reliance on academia to create AI solutions. Some astute organizations quickly seized upon this trend, riding on the big tech model without investing in academia-style research resources, thereby achieving visible results. However, for others, it became a period of confusion, as they attempted to reconcile the strengths of existing business processes with new changes.

One thing is clear: AI engineers are now facing unprecedented demands for commercialization. Gone are the days of merely applauding surface-level achievements or packaging modest results in beautifully crafted reports or AI hype. As AI becomes integrated into the realm of industry, the perception of it as a highly innovative precursor task is evolving, demanding rigorous performance and evaluation standards akin to those in the industry's mainstream.

(Sorce: [Linkedin post](https://www.linkedin.com/in/mark-kim-18431346/recent-activity/all/))
